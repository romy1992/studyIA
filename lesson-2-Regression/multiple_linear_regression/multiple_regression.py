import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Recupero il dataframe
df = pd.read_csv('50_Startups.csv')

# Identifico X e y
X = df.drop('Profit', axis=1).values
y = df['Profit'].values

# Controllo se ci sono valori NaN o Encoder da fare
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

# Split dei dati per costruire il modello
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Addestro il modello
regression = LinearRegression()
regression.fit(X_train, y_train)

# Predict test
y_predict = regression.predict(X_test)
# Per settare i valori numerici con 2 decimali
np.set_printoptions(precision=2)
# ConcatenerÃ  i valori predetti e quelli reali in verticale per confrontarli con piÃ¹ facilitÃ 
print(np.concatenate((y_predict.reshape(len(y_predict), 1), y_test.reshape(len(y_test), 1)), 1))

"""
La regressione lineare multipla Ã¨ un'estensione della regressione lineare semplice e si utilizza quando si vuole 
prevedere una variabile dipendente continua (output) utilizzando piÃ¹ variabili indipendenti (input).
La regressione lineare multipla Ã¨ utile quando il fenomeno che si vuole prevedere Ã¨ influenzato da diversi fattori. 
Ad esempio:
Prezzo di una casa: Potresti volerlo prevedere considerando variabili come la superficie, 
    il numero di stanze, la posizione, l'anno di costruzione, ecc.
Rendimento scolastico: Potrebbe dipendere da fattori come le ore di studio, 
    il supporto familiare, il tipo di scuola, e cosÃ¬ via.
Utilizzare piÃ¹ variabili indipendenti permette al modello di avere una maggiore capacitÃ  di previsione e di catturare 
meglio la complessitÃ  dei dati rispetto alla regressione lineare semplice, che si basa su una sola variabile.

Regressione lineare multipla: Si utilizzano piÃ¹ variabili indipendenti (ğ‘¥1,ğ‘¥2,...,ğ‘¥ğ‘›) 
per prevedere la variabile dipendente (y). L'equazione diventa:
y = Î²0+Î²1x1+Î²2x2+...+Î²nXn+Ïµ

dove:
y Ã¨ la variabile dipendente.
x Ã¨ la variabile indipendente.
Î²0 Ã¨ l'intercetta.(Ã¨ come una sorta di "valore di base" da cui il modello parte per poi aggiungere (o sottrarre) 
    gli effetti delle variabili indipendenti sul valore previsto di ğ‘¦)
Î²1,Î²2,...,Î²n sono i coefficienti di regressione associati alle rispettive variabili indipendenti.
Ïµ Ã¨ il termine di errore.
"""
